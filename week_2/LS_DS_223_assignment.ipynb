{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U7SHMCmhpUV"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 2, Module 3*\n",
    "\n",
    "---\n",
    "<p style=\"padding: 10px; border: 2px solid red;\">\n",
    "    <b>Before you start:</b> Today is the day you should submit the dataset for your Unit 2 Build Week project. You can review the guidelines and make your submission in the Build Week course for your cohort on Canvas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B8S6Xh8BhpUW"
   },
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, validation_curve # k-fold CV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV # Hyperparameter tuning\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNgkmhrRhpUX"
   },
   "source": [
    "# Module Project: Hyperparameter Tuning\n",
    "\n",
    "This sprint, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
    "\n",
    "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
    "\n",
    "## Directions\n",
    "\n",
    "The tasks for this project are as follows:\n",
    "\n",
    "- **Task 1:** Use `wrangle` function to import training and test data.\n",
    "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
    "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
    "- **Task 4:** Build `clf_dt`.\n",
    "- **Task 5:** Build `clf_rf`.\n",
    "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
    "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
    "- **Task 8:** Print out best score and params for model.\n",
    "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
    "\n",
    "You should limit yourself to the following libraries for this project:\n",
    "\n",
    "- `category_encoders`\n",
    "- `matplotlib`\n",
    "- `pandas`\n",
    "- `pandas-profiling`\n",
    "- `sklearn`\n",
    "\n",
    "# I. Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eeviZqYahpUY"
   },
   "outputs": [],
   "source": [
    "# Use wrangle function to import training and test data, and clean\n",
    "def wrangle(fm_path, tv_path=None):\n",
    "    if tv_path:\n",
    "        df = pd.merge(pd.read_csv(fm_path, \n",
    "                                  na_values=[0, -2.000000e-08]),\n",
    "                      pd.read_csv(tv_path)).set_index('id')\n",
    "    else:\n",
    "        df = pd.read_csv(fm_path, \n",
    "                         na_values=[0, -2.000000e-08],\n",
    "                         index_col='id')\n",
    "\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "    \n",
    "    # Drop constant columns\n",
    "    df.drop(columns=['recorded_by'], inplace=True)\n",
    "    \n",
    "    # Create age feature\n",
    "    df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
    "    df.drop(columns=['date_recorded','construction_year'], inplace=True)\n",
    "    \n",
    "    # Drop HCCCs\n",
    "    cutoff = 100\n",
    "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
    "                 if df[col].nunique() > cutoff]\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
    "                 if df.head(15).T.duplicated()[col]]\n",
    "    df.drop(columns=dupe_cols, inplace=True)             \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# Using the above wrangle function to read train_features.csv and train_labels.csv into the DataFrame\n",
    "df = wrangle(fm_path= 'train_features.csv',\n",
    "             tv_path= 'train_labels.csv')\n",
    "\n",
    "# test_features.csv into the DataFrame X_test\n",
    "X_test = wrangle(fm_path= 'test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rckdvO7ihpUY"
   },
   "source": [
    "**Task 1:** Using the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCk4tkyBhpUZ"
   },
   "source": [
    "# II. Split Data\n",
    "\n",
    "**Task 2:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`.\n",
    "\n",
    "**Note:** You won't need to do a train-test split because you'll use cross-validation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PYEEFuhthpUZ"
   },
   "outputs": [],
   "source": [
    "# Split your DataFrame df into a feature matrix X and the target vector y. You want to predict 'status_group'\n",
    "target = 'status_group'\n",
    "y = df[target]\n",
    "X = df.drop(columns=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a randomized split, divide X and y into a training set (X_train, y_train) and a validation set (X_val, y_val)\n",
    "X_train,y_val,y_train,y_val = train_test_split(X,y,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhHjOlOuhpUZ"
   },
   "source": [
    "# III. Establish Baseline\n",
    "\n",
    "**Task 3:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YRTWpQhfhpUa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score: 0.5425489938182296\n"
     ]
    }
   ],
   "source": [
    "# Figure out what is the majority class in y_train and what percentage of your training observations it represents\n",
    "baseline_Acc = y_train.value_counts(normalize=True).max()\n",
    "print('Baseline Accuracy Score:',baseline_Acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYCJKqskhpUa"
   },
   "source": [
    "# IV. Build Models\n",
    "\n",
    "**Task 4:** Build a `Pipeline` named `clf_dt`. Your `Pipeline` should include:\n",
    "\n",
    "- an `OrdinalEncoder` transformer for categorical features.\n",
    "- a `SimpleImputer` transformer fot missing values.\n",
    "- a `DecisionTreeClassifier` Predictor.\n",
    "\n",
    "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "09YUhqFYhpUa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['basin', 'region', 'public_meeting',\n",
       "                                      'scheme_management', 'permit',\n",
       "                                      'extraction_type',\n",
       "                                      'extraction_type_class', 'management',\n",
       "                                      'management_group', 'payment',\n",
       "                                      'payment_type', 'water_quality',\n",
       "                                      'quality_group', 'quantity', 'source',\n",
       "                                      'source_type', 'source_class',\n",
       "                                      'waterpoint_type'],\n",
       "                                mapping=[{'col': 'basin',\n",
       "                                          'data_typ...\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': groundwater    1\n",
       "surface        2\n",
       "unknown        3\n",
       "NaN           -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'waterpoint_type',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': hand pump                      1\n",
       "communal standpipe             2\n",
       "communal standpipe multiple    3\n",
       "improved spring                4\n",
       "other                          5\n",
       "cattle trough                  6\n",
       "dam                            7\n",
       "NaN                           -2\n",
       "dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('decisiontreeclassifier',\n",
       "                 DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Pipeline named clf_dt\n",
    "clf_dt = make_pipeline(OrdinalEncoder(),\n",
    "                        SimpleImputer(strategy='mean'),\n",
    "                        DecisionTreeClassifier(random_state=42))\n",
    "\n",
    "clf_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyWYadDkhpUa"
   },
   "source": [
    "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
    "\n",
    "- an `OrdinalEncoder` transformer for categorical features.\n",
    "- a `SimpleImputer` transformer fot missing values.\n",
    "- a `RandomForestClassifier` predictor.\n",
    "\n",
    "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XAjycwMMhpUb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['basin', 'region', 'public_meeting',\n",
       "                                      'scheme_management', 'permit',\n",
       "                                      'extraction_type',\n",
       "                                      'extraction_type_class', 'management',\n",
       "                                      'management_group', 'payment',\n",
       "                                      'payment_type', 'water_quality',\n",
       "                                      'quality_group', 'quantity', 'source',\n",
       "                                      'source_type', 'source_class',\n",
       "                                      'waterpoint_type'],\n",
       "                                mapping=[{'col': 'basin',\n",
       "                                          'data_typ...\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': groundwater    1\n",
       "surface        2\n",
       "unknown        3\n",
       "NaN           -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'waterpoint_type',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': hand pump                      1\n",
       "communal standpipe             2\n",
       "communal standpipe multiple    3\n",
       "improved spring                4\n",
       "other                          5\n",
       "cattle trough                  6\n",
       "dam                            7\n",
       "NaN                           -2\n",
       "dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 5: Build a Pipeline named clf_rf\n",
    "clf_rf = make_pipeline(OrdinalEncoder(),\n",
    "                         SimpleImputer(strategy='mean'),\n",
    "                         RandomForestClassifier(n_jobs=-1,\n",
    "                                                random_state=42))\n",
    "\n",
    "clf_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qkQB8XLhpUb"
   },
   "source": [
    "# V. Check Metrics\n",
    "\n",
    "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FyCjZrMBhpUb"
   },
   "outputs": [],
   "source": [
    "# Evaluate the performance of both of your classifiers using k-fold cross-validation\n",
    "cv_scores_dt = cross_val_score(clf_dt,X,y,cv=5) \n",
    "cv_scores_rf = cross_val_score(clf_rf,X,y,cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_1Ix3ex7hpUb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores DecisionTreeClassifier\n",
      "[0.74978956 0.75210438 0.74694865 0.75484007 0.7415553 ]\n",
      "Mean CV accuracy score: 0.7490475916519008\n",
      "STD CV accuracy score: 0.004560421783713259\n"
     ]
    }
   ],
   "source": [
    "# Print Results of DecisionTreeClassifier\n",
    "print('CV scores DecisionTreeClassifier')\n",
    "print(cv_scores_dt)\n",
    "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
    "print('STD CV accuracy score:', cv_scores_dt.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "i_6uRZUzhpUc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score RandomForestClassifier\n",
      "[0.79955808 0.79945286 0.79987374 0.80576599 0.80016837]\n",
      "Mean CV accuracy score: 0.8009638082568997\n",
      "STD CV accuracy score: 0.002414166074363791\n"
     ]
    }
   ],
   "source": [
    "# Print Results of RandomForestClassifier\n",
    "print('CV score RandomForestClassifier')\n",
    "print(cv_scores_rf)\n",
    "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
    "print('STD CV accuracy score:', cv_scores_rf.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbtbVgPZhpUc"
   },
   "source": [
    "# VI. Tune Model\n",
    "\n",
    "**Task 7:** Choose the best performing of your two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Make sure that you include cross-validation and that `n_iter` is set to at least `25`.\n",
    "\n",
    "**Note:** If you're not sure which hyperparameters to tune, check the notes from today's guided project and the `sklearn` documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bLPRUun4hpUc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nigel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.80109007        nan 0.75696034        nan        nan\n",
      "        nan 0.80407832 0.80616169        nan        nan        nan\n",
      "        nan 0.78835829 0.79328265 0.80433085        nan 0.80104787\n",
      "        nan 0.75710763 0.79340887 0.75618168 0.80397312        nan\n",
      "        nan 0.79959589 0.80416251 0.79963798        nan 0.80066906\n",
      " 0.75584498 0.8027315         nan 0.75546616        nan 0.80277356\n",
      "        nan 0.75374058        nan        nan 0.79324051 0.79239881\n",
      " 0.72385777        nan        nan        nan        nan 0.79500827\n",
      " 0.79338783        nan        nan 0.72415239 0.7228687         nan\n",
      " 0.72263725 0.79791238 0.80239479 0.75597124 0.7567499         nan\n",
      " 0.72299497 0.78393904        nan        nan        nan 0.75561354\n",
      " 0.80397303 0.78524374        nan        nan        nan        nan\n",
      "        nan 0.7938508  0.80483592 0.7852858  0.7215008  0.72337378\n",
      " 0.80456236 0.80443606 0.8052147         nan        nan 0.80197385\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.756813   0.78503333 0.80435184        nan        nan        nan\n",
      " 0.75592918        nan        nan 0.79389292        nan 0.79300905\n",
      "        nan 0.80433085        nan        nan        nan 0.75637106\n",
      "        nan 0.72318436 0.75736015        nan 0.79246187 0.75435087\n",
      "        nan 0.72360525 0.80439399 0.7588754  0.75418251        nan\n",
      " 0.80127941        nan 0.80014307 0.79389292        nan 0.79128345\n",
      " 0.72202696        nan        nan 0.8023527         nan 0.80430982\n",
      "        nan 0.79391394 0.79309327        nan        nan        nan\n",
      "        nan        nan 0.80321553        nan 0.80523576        nan\n",
      " 0.80466756        nan        nan 0.80496216 0.80292089        nan\n",
      "        nan 0.80504636        nan 0.79155701        nan 0.80300507\n",
      " 0.80529888        nan 0.79136757 0.72337377 0.79340891 0.80279463\n",
      "        nan 0.80418353 0.80599335 0.78955781        nan        nan\n",
      " 0.80302613 0.72394196 0.80262622        nan 0.75544513        nan\n",
      " 0.7938929  0.80466753 0.8047938         nan 0.72343689        nan\n",
      "        nan        nan 0.8049832         nan        nan        nan\n",
      "        nan 0.75677095        nan        nan 0.79475572 0.80430979\n",
      " 0.75605542 0.7229739  0.80517261 0.80281566 0.80102681        nan\n",
      "        nan 0.79313533        nan        nan 0.75435085        nan\n",
      " 0.80435196 0.80250002        nan        nan        nan 0.75599229\n",
      " 0.80127942        nan        nan        nan 0.78515954 0.79991156\n",
      "        nan        nan 0.7960394         nan 0.80428873        nan\n",
      " 0.80424668        nan 0.75674988 0.79281963 0.80500425        nan\n",
      "        nan        nan 0.80447815        nan 0.75635004 0.80412041\n",
      "        nan        nan        nan 0.72131142 0.79376664        nan\n",
      "        nan        nan        nan        nan 0.80222643        nan\n",
      " 0.80353113 0.80496216 0.72350002        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.79641821        nan        nan        nan        nan 0.80348907\n",
      "        nan        nan 0.7995117         nan        nan 0.72114308\n",
      "        nan 0.72356317        nan 0.80222646        nan        nan\n",
      "        nan 0.72406822        nan        nan 0.79391393 0.72263724\n",
      "        nan        nan        nan 0.75757063        nan 0.80188972\n",
      " 0.80386789 0.79241979        nan 0.75776004        nan 0.80424662\n",
      " 0.80470958        nan 0.75731807        nan 0.80285778 0.75517152\n",
      "        nan 0.80319445        nan 0.80306818        nan 0.75658154\n",
      " 0.75721287        nan 0.80233167 0.79143072 0.80167932        nan\n",
      "        nan        nan        nan        nan 0.72381568        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.75578188 0.72194278        nan        nan 0.79968016        nan\n",
      "        nan 0.72356316 0.72453122 0.7212062         nan 0.75567663\n",
      " 0.8052989  0.79481887        nan 0.80538307        nan        nan\n",
      "        nan        nan 0.80180553 0.723016          nan 0.7941665\n",
      "        nan 0.78513852        nan        nan        nan        nan\n",
      "        nan        nan 0.80247894 0.78772698 0.79683906        nan\n",
      " 0.80296304        nan        nan        nan 0.72326853 0.80418348\n",
      "        nan        nan 0.75679195 0.80492008        nan        nan\n",
      " 0.80447822        nan        nan        nan        nan 0.79532392\n",
      "        nan 0.80306818 0.79271445        nan        nan        nan\n",
      " 0.79780712 0.79204098        nan 0.72320543 0.7227635         nan\n",
      "        nan 0.72255304        nan        nan        nan 0.7851385\n",
      " 0.72419447 0.79938544        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('ordinalencoder',\n",
       "                                              OrdinalEncoder()),\n",
       "                                             ('simpleimputer', SimpleImputer()),\n",
       "                                             ('randomforestclassifier',\n",
       "                                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                                     random_state=42))]),\n",
       "                   n_iter=400, n_jobs=-1,\n",
       "                   param_distributions={'randomforestclassifier__max_depth': range(5, 35, 5),\n",
       "                                        'randomforestclassifier__max_features': ['sqrt',\n",
       "                                                                                 'log2'],\n",
       "                                        'randomforestclassifier__max_samples': array([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                        'randomforestclassifier__n_estimators': range(25, 200, 5),\n",
       "                                        'simpleimputer__strategy': ['meadian',\n",
       "                                                                    'mean']},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hoose the best performing of your two models and tune its hyperparameters using a RandomizedSearchCV named model\n",
    "\n",
    "clf = make_pipeline(OrdinalEncoder(),\n",
    "                    SimpleImputer(),\n",
    "                    RandomForestClassifier(random_state=42,n_jobs=-1))\n",
    "\n",
    "param_grid = {'simpleimputer__strategy':['meadian','mean'],\n",
    "             'randomforestclassifier__max_depth':range(5,35,5),\n",
    "             'randomforestclassifier__n_estimators':range(25,200,5),\n",
    "             'randomforestclassifier__max_samples':np.arange(0.2,1,0.1),\n",
    "             'randomforestclassifier__max_features':['sqrt','log2']}\n",
    "\n",
    "model = RandomizedSearchCV(clf,param_distributions = param_grid,\n",
    "                               n_iter=400,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=1)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT0SSKYfhpUc"
   },
   "source": [
    "**Task 8:** Print out the best score and best params for `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F2ygL6RXhpUc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for `model`: 0.8061616905666155\n",
      "Best params for `model`: {'simpleimputer__strategy': 'mean', 'randomforestclassifier__n_estimators': 125, 'randomforestclassifier__max_samples': 0.6000000000000001, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__max_depth': 25}\n"
     ]
    }
   ],
   "source": [
    "# Assign the Best Score \n",
    "best_score = model.best_score_\n",
    "best_params = model.best_params_\n",
    "\n",
    "# Print out the best score and best params for model\n",
    "print('Best score for `model`:', best_score)\n",
    "print('Best params for `model`:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JV7C4MChpUc"
   },
   "source": [
    "# Communicate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBe_pWr4hpUd"
   },
   "source": [
    "**Task 9:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
    "\n",
    "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rca1D3FhhpUd"
   },
   "outputs": [],
   "source": [
    "X_test = X_test[X_train.columns]\n",
    "y_pred = model_rfgs.predict(X_test)\n",
    "submission = pd.DataFrame({'status_group':y_pred}, index=X_test.index)\n",
    "datestamp = pd.Timestamp.now().strftime('%Y-%m-%d_%H%M_')\n",
    "submission.to_csv(f'{datestamp}submission.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_223_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
